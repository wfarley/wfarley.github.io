<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Will Farley]]></title>
  <link href="http://wfarley.github.io/atom.xml" rel="self"/>
  <link href="http://wfarley.github.io/"/>
  <updated>2013-06-08T01:44:08-05:00</updated>
  <id>http://wfarley.github.io/</id>
  <author>
    <name><![CDATA[Will Farley]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Readdit]]></title>
    <link href="http://wfarley.github.io/blog/2013/06/08/readdit/"/>
    <updated>2013-06-08T01:28:00-05:00</updated>
    <id>http://wfarley.github.io/blog/2013/06/08/readdit</id>
    <content type="html"><![CDATA[<h2>Readdit Project</h2>

<p>This is another project I&rsquo;ve wanted to write for quite a while.  Google Reader&rsquo;s RSS feed of Reddit subreddit feeds always annoyed me. Clicking through the article goes to the reddit page, then I have to click through again to go to the actual source article.  I rarely care about the comments on the reddit page.</p>

<p>I wanted to write a simple project to grab the reddit links from the feed, present those in a simple format where I can select which ones to save/read, and store those links.</p>

<p>I have one script to do the article gathering; I pass in the subreddit name and the number of pages (25 articles per page) to parse.  I&rsquo;m using sqlite3 as a simple DB to store everything.  If any new articles are found, they are added to a table in the database for the subreddit.</p>

<p>I have a really simple class wrapper to initialize and close the database and create the table.</p>

<pre><code>def initialize
    @db = SQLite3::Database.new("readdit.db")
    @db.results_as_hash = true
end

def create_table(table_name)
    @db.execute %Q|
        CREATE TABLE IF NOT EXISTS #{table_name} (
            id integer primary key,
            reddit_id varchar(25),
            title varchar(255),
            url varchar(255),
            permalink varchar(255),
            created datetime,
            saved boolean,
            deleted boolean,
            read_date datetime,
            UNIQUE(reddit_id) ON CONFLICT IGNORE
        )
    |
end
</code></pre>

<p>In the script for collecting the articles, I request the JSON feed from Reddit with Net::HTTP.</p>

<pre><code>url_str = "http://www.reddit.com/r/#{ARGV[0]}/.json"

url_str += "?count=#{25 * page}&amp;after=#{after_id}" if page &gt; 0

uri = URI.parse(url_str)

response = Net::HTTP.get_response(uri)

json_str = response.body
</code></pre>

<p>I use the JSON gem to parse the response and turn it into a hash.</p>

<pre><code>rss_data = JSON.parse(json_str)
</code></pre>

<p>The <code>after_id</code> is required to fetch the pages after the initial page, and is found in the main &lsquo;data&rsquo; section.</p>

<pre><code>after_id = rss_data['data']['after']
</code></pre>

<p>All of the articles are in the &lsquo;children&rsquo; section, so I loop through the articles and pull out the data I want to store &ndash; the title of the submission, the url of the linked article, the reddit id, how many comments, whether it is a &ldquo;self&rdquo; article, and when the submission was created.  The permalink field gives the link to reddit so that I can read the comments, etc if desired.</p>

<pre><code>rss_data['data']['children'].each do |rss_article|
    article_data = rss_article['data']


    theDB.db.execute("INSERT INTO #{ARGV[0]}_articles 
                        (reddit_id, title, url, permalink, created) 
                        VALUES (?, ?, ?, ?, ?)",
                             article_data['id'],
                             article_data['title'], 
                              article_data['url'],
                              article_data['permalink'], 
                             article_data['created'])

    self_article = article_data['is_self']
    puts article_data['title']
    puts article_data['url']
    puts article_data['num_comments']
    puts article_data['id']
    puts article_data['is_self']
    puts Time.at(article_data['created'])
    puts article_data['selftext'] if self_article
    puts ""

end
</code></pre>

<p>I then put put together another script to sort and read the articles in the database.  I kept this pretty basic for now.</p>

<p>I get each article that hasn&rsquo;t been read yet:</p>

<pre><code>unread_articles = theDB.db.execute("SELECT * FROM #{ARGV[0]}_articles WHERE read_date IS NULL")
</code></pre>

<p>I loop through the returned articles and wait for a keypress to indicate whether to save the article or mark it as deleted.  I don&rsquo;t actually delete the article at this time &ndash; I want to keep it in the database so that it isn&rsquo;t re-added to the database the next time I run the script to collect articles.</p>

<p>After I get the input I update the row.</p>

<pre><code>unread_articles.each do |article|

    #...

    theDB.db.execute("UPDATE #{ARGV[0]}_articles
                        SET saved = #{save}, deleted = #{delete}, read_date = datetime('now')
                        WHERE id = #{article['id']}")
end
</code></pre>

<p>I throw each saved article into an array, then I just create/open an HTML file and throw each url and permalink into it.</p>

<pre><code>save_list.each do |article|
    save_file.puts "&lt;a href=\"#{article['url']}\"&gt;#{article['title']}&lt;/a&gt; &lt;a href=\"http://www.reddit.com#{article['permalink']}\"&gt;Reddit Link&lt;/a&gt;"
    save_file.puts "&lt;br&gt;"
end
</code></pre>

<p>Now, rather than try to improve this reading list, I want to turn this into a Rails project.  I think it&rsquo;s a perfect fit as a project to start exploring Rails again.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Project - Photo Filter]]></title>
    <link href="http://wfarley.github.io/blog/2013/05/18/project-photo-filter/"/>
    <updated>2013-05-18T01:00:00-05:00</updated>
    <id>http://wfarley.github.io/blog/2013/05/18/project-photo-filter</id>
    <content type="html"><![CDATA[<p>I wanted to tackle this project first for a few reasons.  It&rsquo;s a task that lends itself to automation, has a small scope, and was relatively simple, so I should be able to complete it quickly.</p>

<h2>The Project</h2>

<p>After we import new photos into Lightroom, they get edited, then all get exported as JPGs to a folder on the desktop.  After the export completes, we move the photos into a year/month directory structure on our home server.</p>

<p>It has a few different pieces to it which I&rsquo;ve not worked with before, but have been interested in learning.</p>

<h3>The Launch Agent</h3>

<p>I wanted to monitor the export folder, and have the script kicked off automatically, rather than manually running the script after the export completed.</p>

<p><code>launchd</code> is perfect, and this gives me good reason to get experience with it.</p>

<p>My final launchd script looks like this:</p>

<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;
&lt;plist version="1.0"&gt;
&lt;dict&gt;
    &lt;key&gt;Label&lt;/key&gt;
    &lt;string&gt;org.willf.photo_filter&lt;/string&gt;
    &lt;key&gt;ProgramArguments&lt;/key&gt;
    &lt;array&gt;
        &lt;string&gt;ruby&lt;/string&gt;
        &lt;string&gt;/Users/will/Dropbox/Development/Scripts/file_photos.rb&lt;/string&gt;
          &lt;string&gt;/Users/will/Desktop/New Pics/&lt;/string&gt;
    &lt;/array&gt;
    &lt;key&gt;WatchPaths&lt;/key&gt;
     &lt;array&gt;
          &lt;string&gt;/Users/will/Desktop/New Pics&lt;/string&gt;
     &lt;/array&gt;
&lt;/dict&gt;
&lt;/plist&gt;
</code></pre>

<p>Initially, I tried to use the <code>QueueDirectories</code> key instead of WatchPaths. It is more
inline with what I need, however there was a problem with using it.  For <code>QueueDirectories</code>, the launch agent starts whenever the given directories on not empty, i.e. once files are added, and will not start again until after those directories
are empty.  The problem is that the directory I want to monitor can and will be occasionally visited in Finder, which places a hidden .DS_Store in the directory. I didn&rsquo;t want to deal with monitoring and constantly erasing that file, and risk the launch agent not starting because of that file.</p>

<p>So I went with WatchPaths, which starts the launch agent whenever the path changes. This has worked out fine.</p>

<h3>The Script</h3>

<p>When the ruby script gets kicked off by the launch agent, it first starts watching the directory.  Every three minutes, it checks the directory to see if the list of files in the directory has changed.</p>

<pre><code># Wait for export of all photos to the directory to be completed
def WaitForDirectory(dirName)
    prev_all_files = []
    all_files = Dir.entries(dirName)

    while (prev_all_files.sort != all_files.sort)
        sleep(WAIT_TIME)
        prev_all_files = all_files
        all_files = Dir.entries(dirName)
    end
end
</code></pre>

<p>The exports from Lightroom usually take quite a while, since we export a large group of images normally. If no new files have been added to the directory in the last three minutes, I assume the export has completed and get on with the script.</p>

<p>I&rsquo;m using the <code>exifr</code> (EXIF Reader) gem to read the EXIF data of the images.  It is easy to setup and use, and works quite well for my needs.</p>

<p>I pull each JPG file in the directory and read its EXIF data, pulling out the image&rsquo;s original year and month.</p>

<pre><code>year = exif_data.exif.date_time_original.year
month = exif_data.exif.date_time_original.strftime("%B")
</code></pre>

<p>The <code>%B</code> argument in <code>strftime</code> gives me the full month name (i.e. &ldquo;January&rdquo;).  I create (if necessary, with <code>FileUtils.mkdir_p</code>) a directory structure at the same level as the folder I&rsquo;m watching with that mirrors the same structure as the server folder layout.  I then move the image file to its new location.</p>

<p>Once I process and move each photo to its new location, I make sure the server volume is mounted.  If not, I run a shell script to mount it.</p>

<pre><code>#! /bin/bash
if [ ! -d "/Volumes/Photos" ]; then
   automator /Users/will/Dropbox/Development/Scripts/MountPhotosVolume.app
fi
</code></pre>

<p>Using Automator was another new learning experience for me.  There&rsquo;s other ways I could have mounted it, but I wanted to check out Autmator, and it works well.</p>

<p>(I also added another launch agent which periodically runs this script, to attempt to make sure this volume is always mounted.)</p>

<p>After it runs the shell script, it waits 10 seconds for the volume to mount, then uses <code>FileUtils.cp_r</code> to copy the files directly to the server with the same layout.</p>

<h3>Potential Add-Ons</h3>

<p>I would like to automate the task of verifying that all of were copied to the server correctly.  I also need to add another check to abort if the volume doesn&rsquo;t get mounted for some reason by the shell script.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Starting Out]]></title>
    <link href="http://wfarley.github.io/blog/2013/05/15/starting-out/"/>
    <updated>2013-05-15T11:25:00-05:00</updated>
    <id>http://wfarley.github.io/blog/2013/05/15/starting-out</id>
    <content type="html"><![CDATA[<p>I had a few goals &ndash; to start working on projects again, even if they were small, learning ruby, working more with git, and start a dev blog.  For the blog I was interested in using a Jekyll based blog for the experience, and since it&rsquo;s ruby based, give me more ruby projects to potentially work with.  I want to start out with a small scope for the blog, just dev stuff, but I&rsquo;ll just write and see where it goes.</p>

<p>For a first ruby project, I wanted to tackle a task I&rsquo;ve wanted to automate for years &ndash; sorting photos and moving them into their proper directory on our home server.</p>
]]></content>
  </entry>
  
</feed>
